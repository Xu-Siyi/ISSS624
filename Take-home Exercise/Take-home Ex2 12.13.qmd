---
title: "Take-home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods"
author: "Xu Siyi"
format: html
editor: visual
---

## Overview

## Getting Started

```{r}
pacman::p_load(sf,spdep, tmap, tidyverse,dplyr, funModeling,rgdal,  ClustGeo, ggpubr, cluster, factoextra, NbClust,heatmaply, corrplot, psych, GGally)
```

## Data Import

### Import water point data

```{r}
#| eval: false
wp <- read_csv("Take home 2 data/WPdx.csv",show_col_types = FALSE) %>%
  filter(`#clean_country_name` == "Nigeria")
```

-   I use `show_col_types = FALSE` to avoid warning message.

-   To extract Nigeria data I use `filter()`

I saved it into wp_nga.rds. In this way I can delete geo_export data which is too large to git push.

```{r}
#| eval: false

wp_nga<-write_rds(wp,"Take home 2 data/wp_nga.rds")
```

```{r}

wp_nga <- read_rds("Take home 2 data/wp_nga.rds") 
```

#### Convert wkt data

Column '*New Georaferenced Column*' represent spatial data in a textual format. this kind of text file is popularly known as **Well Known Text** in short **wkt**.

![](images/paste-D42CF081.png)

Two steps will be used to convert an asptial data file in wkt format into a sf data frame by using sf.

First, `st_as_sfc()` of sf package is used to derive a new field called *Geometry* as shown in the code chunk below.

```{r}
#| eval: false
wp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)
```

Now we get the new column called Geometry.

![](images/paste-0F5EA02B.png)

Next, `st_sf()` will be used to convert the tibble data frame into sf data frame.

```{r}
wp_sf <- st_sf(wp_nga, crs=4326) 
```

When the process completed, a new sf data frame called *wp_sf* will be created.

### Importing Nigeria LGA level boundary data

```{r}
nga<- st_read(dsn="Take home 2 data",
             layer="geoBoundaries-NGA-ADM2",
             crs=4326)
```

### Point in Polygon Overlay

To make sure the data accuracy, we are going to use a geoprocessing function (or commonly know as GIS analysis) called **point-in-polygon overlay** to transfer the attribute information in *nga* sf data frame into *wp_sf* data frame.

```{r}
wp_sf <- st_join(wp_sf, nga)%>%
  mutate(status_cle = replace_na(status_cle, "Unknown")) %>%
  mutate(X_water_tec = replace_na(X_water_tec, "Unknown"))
```

Now we have column called "shapeName", which is the LGA name of Nigeria water point.

![](images/paste-548FE3DC.png)

## Data Wrangling

The reference of the code chunk in Data Wrangling part: [Ong Zhi Rong Jordan](https://jordan-isss624-geospatial.netlify.app/posts/geo/geospatial_exercise/#visualising-of-distribution-using-ggplot)

### **Checking of duplicated area name**

We use `duplicate` function to retrieve all the shapeName that has duplicates and store it in a list. From the result below, we identified **12** shapeNames that are duplicates.

```{r}
nga <- (nga[order(nga$shapeName), ])

duplicate_area <- nga$shapeName[ nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]

duplicate_area
```

Next, we will leverage on the interactive viewer of `tmap` to check the location of each area. Through the use of Google, we are able to retrieve the actual name and state of the areas. The table below shows the index and the actual name of the area.

| Index | Actual Area Name |
|-------|------------------|
| 94    | Bassa (Kogi)     |
| 95    | Bassa (Plateau)  |
| 304   | Ifelodun (Kwara) |
| 305   | Ifelodun (Osun)  |
| 355   | Irepodun (Kwara) |
| 356   | Irepodun (Osun)  |
| 518   | Nassarawa        |
| 546   | Obi (Benue)      |
| 547   | Obi(Nasarawa)    |
| 693   | Surulere (lagos) |
| 694   | Surulere (Oyo)   |

```{r}
tmap_mode("view")

tm_shape(nga[nga$shapeName %in% duplicate_area,]) +
  tm_polygons()
```

Make sure the tmap mode set back to plot

```{r}
tmap_mode("plot")
```

We will now access the individual index of the `nga` data frame and change the value. Lastly, we use the [`length()`](https://rdrr.io/r/base/length.html) function to ensure there is no more duplicated shapeName.

```{r}
nga$shapeName[c(94,95,304,305,355,356,519,546,547,693,694)] <- c("Bassa (Kogi)","Bassa (Plateau)",
                                                                               "Ifelodun (Kwara)","Ifelodun (Osun)",
                                                                               "Irepodun (Kwara)","Irepodun (Osun)",
                                                                               "Nassarawa","Obi (Benue)","Obi(Nasarawa)",
                                                                               "Surulere (Lagos)","Surulere (Oyo)")

length((nga$shapeName[ nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]))
```

### **Projection of sf dataframe**

```{r}
#| eval: false
wp_sf <- st_as_sf(nga, coords = c("long", "lat"),  crs = 4326)
```

## Derive new variables

::: callout-caution
## Take-home Exercise 2 Objective

In this take-home exercise you are required to regionalise Nigeria by using, but not limited to the following measures:

-   Total number of functional water points

-   Total number of nonfunctional water points

-   Percentage of functional water points

-   Percentage of non-functional water points

-   Percentage of main water point technology (i.e. Hand Pump)

-   Percentage of usage capacity (i.e. \< 1000, \>=1000)

-   Percentage of rural water points
:::

In this section, we will extract the water point records by using classes in status_cle field.

in this code chunk below, filter() is used to select functional water points

```{r}
wpt_functional <- wp_sf %>%
  filter(status_cle %in%
           c("Functional", 
             "Functional but not in use",
             "Functional but needs repair"))
```

In the code chunk below, filter() of dplyr is used to select non-functional water points.

```{r}
wpt_nonfunctional <- wp_sf %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

In the code chunk below, `filter()` of dplyr is used to select water points with unknown status.

```{r}
wpt_unknown <- wp_sf %>%
  filter(status_cle == "Unknown")
```

```{r}
wpt_handpump <- wp_sf %>%
  filter(X_water_tec == "Hand Pump")
```

```{r}
usage_low <- wp_sf %>%
  filter(`usage_cap` < 1000)
```

```{r}
usage_high <- wp_sf %>%
  filter(`usage_cap` >= 1000)
```

```{r}
wpt_rural<-wp_sf %>%
  filter(`is_urban` == "False")
```

Then we add new variable called total wpt, wpt functional, wpt non-functional, wpt unknown, wpt handpump, usage low, usage high, \`wpt rural into nga dataframe.

```{r}
nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_sf))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt unknown` = lengths(
    st_intersects(nga, wpt_unknown)))%>%
  mutate(`wpt handpump` = lengths(
    st_intersects(nga, wpt_handpump)))%>%
  mutate(`usage low` = lengths(
    st_intersects(nga, usage_low)))%>%
  mutate(`usage high` = lengths(
    st_intersects(nga, usage_high)))%>%
  mutate(`wpt rural` = lengths(
    st_intersects(nga, wpt_rural)))
```

Then we can calculate the percentage of functional water point and non-functional water points, the percentage of Hand Pump, the percentage of usage capacity and the percentage of rural water points

```{r}
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt functional`/`total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%
  mutate(`pct_handpump` = `wpt handpump`/`total wpt`) %>%
  mutate(`pct_usagelow` = `usage low`/`total wpt`) %>%
  mutate(`pct_usagehigh` = `usage high`/`total wpt`) %>%
  mutate(`pct_rural` = `wpt rural`/`total wpt`)
```

Things to learn from the code chunk above:

`mutate()` of **dplyr** package is used to derive two fields namely pct_functional and pct_non-functional.

There are some NaN field in the nga_wp because of the zero number of total water point. I replace them with zero value.

```{r}
nga_wp <- nga_wp %>%
  mutate(pct_functional = replace_na(pct_functional, 0)) %>%
  mutate(`pct_non-functional` = replace_na(`pct_non-functional`, 0)) %>%
  mutate(pct_handpump = replace_na(pct_handpump, 0)) %>%
  mutate(pct_usagelow = replace_na(pct_usagelow, 0)) %>%
  mutate(pct_usagehigh = replace_na(pct_usagehigh, 0)) %>%
  mutate(pct_rural = replace_na(pct_rural, 0))
```

```{r}
wp_sf <- st_transform(wp_sf, crs = 26391)

st_crs (wp_sf)
```

Now, I have the tidy sf data table subsequent analysis and save the sf data table into rds format. `nga_wp.rds`, which is the combination of the geospatial and aspatial data.

```{r}
write_rds(nga_wp, "Take home 2 data/nga_wp.rds")
```

## Exploratory Data Analysis (EDA)

```{r}
nga_wp <- read_rds("Take home 2 data/nga_wp.rds")
```

### EDA using statistical graphics

Firstly, I plot the distribution of the variables (i.e. Number of functional water point) by using bar graph.

```{r,fig.height=3,fig.width=7}
freq(data=wp_sf, 
     input = 'status_cle')
```

From the graph above we can see there are 48.29% water points in Nigeria are functional. 30.93% water points are non-functional and 11.22% water points are unknown.

```{r,fig.height=3,fig.width=7}
freq(data=wp_sf, 
     input = 'X_water_tec')
```

From the above graph we can see that 61.84% of all water points in Nigeria are hand pump, 26.99% are mechanized pump and 10.58% are unknown.

```{r,fig.height=3,fig.width=7}
freq(data=wp_sf, 
     input = 'is_urban')
```

From the above graph we can see that 79.14% of all water points in Nigeria are rural, 20.59% are urban.

Secondly, I plot the distribution of the variables (i.e. Number of functional water point) by using historgram graph.

```{r}
pct_functional <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pct_nonfunctional <- ggplot(data=nga_wp, 
             aes(x= `pct_non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pct_handpump <- ggplot(data=nga_wp, 
           aes(x= `pct_handpump`)) +
geom_histogram(bins=20, 
               color="black", 
                 fill="light blue")

pct_usagelow <- ggplot(data=nga_wp, 
             aes(x= `pct_usagelow`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pct_usagehigh <- ggplot(data=nga_wp, 
             aes(x= `pct_usagehigh`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pct_rural <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

```{r}
#| fig-width: 6
#| fig-height: 5
ggarrange(pct_functional, pct_nonfunctional,pct_handpump, pct_usagehigh, pct_usagelow, pct_rural, 
          ncol = 3, 
          nrow = 2)
```

### EDA using choropleth map

I prepared a choropleth map to have a quick look at the distribution of water point in Nigeria

The code chunks below are used to prepare the choroplethby using the *qtm()* function of **tmap** package.

```{r}
qtm(nga_wp, "total wpt")
```

```{r}
#| fig-width: 9
#| fig-height: 8
func.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_functional",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

nonfunc.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_non-functional",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

handpump.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_handpump",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

usagelow.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_usagelow",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

usagehigh.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_usagehigh",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

rural.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_rural",
          n = 5,
          style = "jenks") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(func.map, nonfunc.map,handpump.map,usagelow.map,usagehigh.map,rural.map,
             asp=NA, ncol=2)
```

## Correlation Analysis

```{r}
nga_wp_cor <- nga_wp %>%
  st_drop_geometry() %>%
  select("shapeName","wpt functional","wpt non-functional", "pct_functional", "pct_non-functional", "pct_handpump","pct_usagelow","pct_usagehigh", "pct_rural")
cluster_vars.cor = cor(nga_wp_cor[,2:8])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

## **Hierarchy Cluster Analysis**

### **Extracting clustering variables**

```{r}
cluster_vars <- nga_wp_cor %>%
  select("shapeName","wpt functional","wpt non-functional","pct_functional", "pct_non-functional", "pct_handpump","pct_usagelow","pct_usagehigh", "pct_rural")
head(cluster_vars,10)
```

Next, we need to change the rows by shape name instead of row number by using the code chunk below.

```{r}
row.names(cluster_vars) <- cluster_vars$"shapeName"
head(cluster_vars,10)
```

Notice that the row number has been replaced into the township name.

Now, we will delete the Shape Name field by using the code chunk below.

```{r}
nga_wp_clu <- select(cluster_vars, c(2:9))
head(nga_wp_clu, 10)
```

### Data Standardisation

In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis

#### Min-Max standardisation

In the code chunk below, *normalize()* of [*heatmaply*](https://cran.r-project.org/web/packages/heatmaply/) package is used to stadardisation the clustering variables by using Min-Max method. The *summary()* is then used to display the summary statistics of the standardised clustering variables.

```{r}
nga_wp_clu.std <- normalize(cluster_vars)
summary(nga_wp_clu.std)
```

Notice that the values range of the Min-max standardised clustering variables are 0-1 now.

#### Z-score standardisation

Z-score standardisation can be performed easily by using [*scale()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale) of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.

I wont use Z score standardisation because not all variables come from normal distribution.

### **Visualising the standardised clustering variables**

```{r}
r <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

nga_clu_s_df <- as.data.frame(nga_wp_clu.std)
s <- ggplot(data=nga_clu_s_df, 
       aes(x=`pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

ggarrange(r, s,
          ncol = 2,
          nrow = 1)
```

```{r}
r <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Raw values without standardisation")

nga_clu_s_df <- as.data.frame(nga_wp_clu.std)
s <- ggplot(data=nga_clu_s_df, 
       aes(x=`pct_functional`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Min-Max Standardisation")

ggarrange(r, s,
          ncol = 2,
          nrow = 1)
```

### Computing proximity matrix

The code chunk below is used to compute the proximity matrix using *euclidean* method.

```{r}
proxmat <- dist(nga_wp_clu, method = 'euclidean')
```

The code chunk below can then be used to list the content of *proxmat* for visual inspection.

```{r}
#| eval: false
proxmat
```

### Computing hierarchical clustering

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

```{r}
#| fig-width: 14
#| fig-height: 10
plot(hclust_ward, cex = 0.6)
```

### Selecting the optimal clustering algorithm

The code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.

Values closer to 1 suggest strong clustering structure.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(nga_wp_clu, method = x)$ac
}

map_dbl(m, ac)
```

With reference to the output above, we can see that **Ward\'s method, which value=0.998 is most closer to 1 provides the strongest clustering structure among the four methods assessed.** Hence, in the subsequent analysis, only Ward\'s method will be used.

### Determining Optimal Clusters

There are three commonly used methods to determine the optimal clusters, they are:

-   Elbow Method

-   Average Silhouette Method

-   Gap Statistic Method

#### Gap Statistic Method

```{r}
set.seed(12345)
gap_stat <- clusGap(nga_wp_clu, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

```{r}
fviz_gap_stat(gap_stat)
```

With reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, **the 5-cluster gives the largest gap statistic and should be the next best cluster to pick.**

### Interpreting the dendrograms

```{r}
#| fig-width: 14
#| fig-height: 10
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 5, 
            border = 2:5)
```

### Visually-driven hierarchical clustering analysis

With **heatmaply**, we are able to build both highly interactive cluster heatmap or static cluster heatmap.

#### Transforming the data frame into a matrix

```{r}
nga_wp_clu_mat <- data.matrix(nga_wp_clu)
```

#### Plotting interactive cluster heatmap using *heatmaply()*

```{r}
#| fig-width: 10
#| fig-height: 14
heatmaply(normalize(nga_wp_clu_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 5,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Nigeria by Water point indicators",
          xlab = "Water point indicators Indicators",
          ylab = "Shape Name of Nigeria"
          )
```

### Mapping the clusters formed

```{r}
groups <- as.factor(cutree(hclust_ward, k=5))
```

```{r}
nga_wp_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
qtm(nga_wp_cluster, "CLUSTER")
```

## Spatially Constrained Clustering: SKATER approach

### Converting into SpatialPolygonsDataFrame

First, I convert `nga_wp` into SpatialPolygonsDataFrame. This is because SKATER function only support **sp** objects such as SpatialPolygonDataFrame.

The code chunk below uses [*as_Spatial()*](https://r-spatial.github.io/sf/reference/coerce-methods.html) of **sf** package to convert `nga_wp`into a SpatialPolygonDataFrame called *`nga_sp`*.

```{r}
nga_sp <- as_Spatial(nga_wp)
```

### Computing Neighbour List

[poly2nb](https://rdrr.io/cran/spdep/man/poly2nb.html)

```{r}
nga.nb <- poly2nb(nga_sp, snap = 0.00010)
summary(nga.nb)
```

```{r}
plot(nga_sp, 
     border=grey(.5))
plot(nga.nb, 
     coordinates(nga_sp), 
     col="blue", 
     add=TRUE)
```

### Computing minimum spanning tree

#### Calculating edge costs

```{r}
lcosts <- nbcosts(nga.nb, nga_wp_clu)
```

```{r}
#nga.w <- nb2listw(nga.nb, 
#                   lcosts, 
#                   style="B")
#summary(nga.w)
```

```{r}

```

```{r}

```

## Spatially Constrained Clustering: ClustGeo Method

### Ward-like hierarchical clustering: ClustGeo

To perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 5, 
            border = 2:5)
```

#### Mapping the clusters formed

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=5))
```

```{r}
nga_wp_ngeo_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

```{r}
qtm(nga_wp_ngeo_cluster, "CLUSTER")
```

### Spatially Constrained Hierarchical Clustering

Before we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using [`st_distance()`](https://r-spatial.github.io/sf/reference/geos_measures.html) of sf package.

```{r}
dist <- st_distance(nga_wp, nga_wp)
distmat <- as.dist(dist)
```

Notice that `as.dist()` is used to convert the data frame into matrix.

Next, `choicealpha()` will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=5, graph = TRUE)
```

With reference to the graphs above, alpha = 0.1 will be used as shown in the code chunk below.

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.1)
```

```{r}
groups <- as.factor(cutree(clustG, k=5))
```

```{r}
nga_wp_Gcluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

```{r}
qtm(nga_wp_Gcluster, "CLUSTER")
```

## Visual Interpretation of Clusters

### Multivariate Visualisation

Past studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package

```{r}
#| fig-width: 14
#| fig-height: 8
ggparcoord(data = nga_wp_ngeo_cluster, 
           columns = c(14:19), 
           groupColumn = "CLUSTER",
           scale = "std",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of water points Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30)) +
  scale_color_viridis(option = "D", discrete=TRUE)
```

The parallel coordinate plot above reveals that

we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.

In the code chunk below, `group_by()` and `summarise()` of dplyr are used to derive mean values of the clustering variables.

```{r}
nga_wp_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(mean_pct_functional = mean(pct_functional),
            mean_pct_non.functional = mean(pct_non.functional),
            mean_pct_handpump = mean(pct_handpump),
            mean_pct_usagelow = mean(pct_usagelow),
            mean_pct_usagehigh = mean(pct_usagehigh),
            mean_pct_rural = mean(pct_rural))
```

```{r}
nga_wp_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(median_pct_functional = median(pct_functional),
            median_pct_non.functional = median(pct_non.functional),
            median_pct_handpump = median(pct_handpump),
            median_pct_usagelow = median(pct_usagelow),
            median_pct_usagehigh = median(pct_usagehigh),
            median_pct_rural = median(pct_rural))
```

```{r}
nga_wp_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(sd_pct_functional = sd(pct_functional),
            sd_pct_non.functional = sd(pct_non.functional),
            sd_pct_handpump = sd(pct_handpump),
            sd_pct_usagelow = sd(pct_usagelow),
            sd_pct_usagehigh = sd(pct_usagehigh),
            sd_pct_rural = sd(pct_rural))
```

```{r}

```
